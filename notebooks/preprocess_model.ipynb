{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet121 Model Preprocessing\n",
    "\n",
    "This notebook preprocesses the DenseNet121 model state dict to make it compatible with torchvision's DenseNet121 implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    \n",
    "# Ensure Models directory exists\n",
    "Path('Models').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Original Model\n",
    "\n",
    "Load the original state dict and examine its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: Models/DenseNet121.pt\n",
      "\n",
      "Original state dict structure:\n",
      "  backbone.0.conv0.weight\n",
      "  backbone.0.norm0.weight\n",
      "  backbone.0.norm0.bias\n",
      "  backbone.0.norm0.running_mean\n",
      "  backbone.0.norm0.running_var\n",
      "  ...\n",
      "\n",
      "Total parameters: 7,037,625\n"
     ]
    }
   ],
   "source": [
    "# Load original state dict\n",
    "original_path = Path('Models/DenseNet121.pt')\n",
    "if not original_path.exists():\n",
    "    raise FileNotFoundError(f\"Original model file not found at: {original_path}\")\n",
    "\n",
    "print(f\"Loading model from: {original_path}\")\n",
    "state_dict = torch.load(original_path)\n",
    "\n",
    "# Print original keys structure\n",
    "print(\"\\nOriginal state dict structure:\")\n",
    "for key in list(state_dict.keys())[:5]:\n",
    "    print(f\"  {key}\")\n",
    "print(\"  ...\")\n",
    "\n",
    "# Print total number of parameters\n",
    "print(f\"\\nTotal parameters: {sum(v.numel() for v in state_dict.values()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create New Model\n",
    "\n",
    "Initialize a fresh DenseNet121 model and examine its expected structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing new DenseNet121...\n",
      "\n",
      "Expected model structure:\n",
      "  features.conv0.weight\n",
      "  features.norm0.weight\n",
      "  features.norm0.bias\n",
      "  features.norm0.running_mean\n",
      "  features.norm0.running_var\n",
      "  ...\n",
      "\n",
      "Total parameters: 8,062,625\n"
     ]
    }
   ],
   "source": [
    "# Initialize new DenseNet121\n",
    "print(\"Initializing new DenseNet121...\")\n",
    "new_model = models.densenet121(weights=None)\n",
    "\n",
    "# Print expected keys structure\n",
    "print(\"\\nExpected model structure:\")\n",
    "model_state = new_model.state_dict()\n",
    "for key in list(model_state.keys())[:5]:\n",
    "    print(f\"  {key}\")\n",
    "print(\"  ...\")\n",
    "\n",
    "# Print total parameters\n",
    "print(f\"\\nTotal parameters: {sum(v.numel() for v in model_state.values()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess State Dict\n",
    "\n",
    "Convert the original state dict to match the expected structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new state dict with correct mapping...\n",
      "\n",
      "New state dict structure:\n",
      "  features.conv0.weight\n",
      "  features.norm0.weight\n",
      "  features.norm0.bias\n",
      "  features.norm0.running_mean\n",
      "  features.norm0.running_var\n",
      "  ...\n",
      "\n",
      "Mapped parameters: 7,037,625\n",
      "\n",
      "Verifying tensor shapes:\n",
      "  features.conv0.weight: torch.Size([64, 3, 7, 7]) -> torch.Size([64, 3, 7, 7])\n",
      "  features.norm0.weight: torch.Size([64]) -> torch.Size([64])\n",
      "  features.norm0.bias: torch.Size([64]) -> torch.Size([64])\n",
      "  features.norm0.running_mean: torch.Size([64]) -> torch.Size([64])\n",
      "  features.norm0.running_var: torch.Size([64]) -> torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Create new state dict with correct mapping\n",
    "print(\"Creating new state dict with correct mapping...\")\n",
    "new_state_dict = OrderedDict()\n",
    "\n",
    "# Track parameter count to verify mapping\n",
    "param_count = 0\n",
    "\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('backbone.0.'):\n",
    "        # Remove backbone.0. prefix and map to features\n",
    "        new_key = k.replace('backbone.0.', 'features.')\n",
    "        new_state_dict[new_key] = v\n",
    "        param_count += v.numel()\n",
    "\n",
    "print(\"\\nNew state dict structure:\")\n",
    "for key in list(new_state_dict.keys())[:5]:\n",
    "    print(f\"  {key}\")\n",
    "print(\"  ...\")\n",
    "\n",
    "print(f\"\\nMapped parameters: {param_count:,}\")\n",
    "\n",
    "# Verify shapes match\n",
    "print(\"\\nVerifying tensor shapes:\")\n",
    "for key in list(new_state_dict.keys())[:5]:\n",
    "    if key in model_state:\n",
    "        print(f\"  {key}: {new_state_dict[key].shape} -> {model_state[key].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate and Save\n",
    "\n",
    "Test loading the preprocessed state dict and save if successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load preprocessed state dict...\n",
      "\n",
      "Missing keys: 2\n",
      "First few missing keys:\n",
      "  classifier.weight\n",
      "  classifier.bias\n",
      "\n",
      "Unexpected keys: 0\n",
      "\n",
      "Saved preprocessed model to: DenseNet121_processed.pt\n"
     ]
    }
   ],
   "source": [
    "# Try loading the state dict\n",
    "print(\"Attempting to load preprocessed state dict...\")\n",
    "try:\n",
    "    missing_keys, unexpected_keys = new_model.load_state_dict(new_state_dict, strict=False)\n",
    "    \n",
    "    print(f\"\\nMissing keys: {len(missing_keys)}\")\n",
    "    if missing_keys:\n",
    "        print(\"First few missing keys:\")\n",
    "        for key in missing_keys[:5]:\n",
    "            print(f\"  {key}\")\n",
    "    \n",
    "    print(f\"\\nUnexpected keys: {len(unexpected_keys)}\")\n",
    "    if unexpected_keys:\n",
    "        print(\"First few unexpected keys:\")\n",
    "        for key in unexpected_keys[:5]:\n",
    "            print(f\"  {key}\")\n",
    "    \n",
    "    if not missing_keys and not unexpected_keys:\n",
    "        print(\"\\nState dict loaded successfully!\")\n",
    "        \n",
    "    # Save preprocessed state dict\n",
    "    output_path = 'DenseNet121_processed.pt'\n",
    "    torch.save(new_state_dict, output_path)\n",
    "    print(f\"\\nSaved preprocessed model to: {output_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error processing state dict: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Saved Model\n",
    "\n",
    "Load the saved preprocessed model to verify it works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved preprocessed model...\n",
      "Successfully loaded preprocessed model!\n",
      "Model parameters: 7,978,856\n"
     ]
    }
   ],
   "source": [
    "# Try loading the saved preprocessed model\n",
    "try:\n",
    "    output_path = Path('DenseNet121_processed.pt')\n",
    "    if not output_path.exists():\n",
    "        raise FileNotFoundError(f\"Processed model file not found at: {output_path}\")\n",
    "        \n",
    "    # Load the saved state dict\n",
    "    print(\"Loading saved preprocessed model...\")\n",
    "    processed_state_dict = torch.load(output_path)\n",
    "    \n",
    "    # Create a fresh model and load the state dict\n",
    "    test_model = models.densenet121(weights=None)\n",
    "    test_model.load_state_dict(processed_state_dict, strict=False)\n",
    "    \n",
    "    print(\"Successfully loaded preprocessed model!\")\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in test_model.parameters()):,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error verifying saved model: {str(e)}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
